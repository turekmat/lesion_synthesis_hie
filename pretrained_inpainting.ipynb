{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stažení brain2vec repozitáře\n",
    "!git clone https://huggingface.co/radiata-ai/brain2vec\n",
    "%cd brain2vec\n",
    "\n",
    "# Instalace git-lfs a stažení modelových vah\n",
    "!apt-get update\n",
    "!apt-get install -y git-lfs\n",
    "!git lfs install\n",
    "!git lfs pull\n",
    "\n",
    "# Instalace potřebných knihoven\n",
    "!pip install -r requirements.txt\n",
    "!pip install SimpleITK nibabel\n",
    "\n",
    "# Vytvoření potřebných adresářů\n",
    "!mkdir -p ae_cache ae_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/brain2vec/preprocess_data.py\n",
    "\n",
    "from itertools import product\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "import re\n",
    "from scipy.ndimage import gaussian_filter, binary_dilation\n",
    "\n",
    "def convert_mha_to_nifti(mha_file, output_dir):\n",
    "    \"\"\"\n",
    "    Převede jeden MHA soubor na NIfTI formát.\n",
    "    \n",
    "    Args:\n",
    "        mha_file: Cesta k MHA souboru\n",
    "        output_dir: Výstupní adresář pro uložení NIfTI souborů\n",
    "        \n",
    "    Returns:\n",
    "        Cesta k vytvořenému NIfTI souboru\n",
    "    \"\"\"\n",
    "    # Načtení MHA souboru\n",
    "    img = sitk.ReadImage(mha_file)\n",
    "    \n",
    "    # Převod na numpy - bez interpolace\n",
    "    data = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    # Normalizace dat\n",
    "    data = np.clip(data, 0, None)\n",
    "    if data.max() > 0:\n",
    "        data = data / data.max()\n",
    "    \n",
    "    # Pro léze zajistíme binární masku\n",
    "    if 'lesion' in mha_file.lower():\n",
    "        data = (data > 0.1).astype(np.float32)\n",
    "    \n",
    "    # Vytvoření afinní matice pro zachování orientace\n",
    "    direction = np.array(img.GetDirection()).reshape(3, 3)\n",
    "    spacing = np.array(img.GetSpacing())\n",
    "    origin = np.array(img.GetOrigin())\n",
    "    \n",
    "    affine = np.eye(4)\n",
    "    affine[:3, :3] = direction * np.expand_dims(spacing, 1)\n",
    "    affine[:3, 3] = origin\n",
    "    \n",
    "    # Vytvoření a uložení NIfTI\n",
    "    nifti_img = nib.Nifti1Image(data, affine)\n",
    "    base_name = os.path.basename(mha_file).replace('.mha', '.nii.gz')\n",
    "    output_path = os.path.join(output_dir, base_name)\n",
    "    nib.save(nifti_img, output_path)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Definujeme cesty k datům v Kaggle\n",
    "pseudo_healthy_dir = '/kaggle/input/pseudohealthy-masked/masked_pseudohealthy'\n",
    "adc_dir = '/kaggle/input/bonbid-2023-train/BONBID2023_Train/1ADC_ss'\n",
    "label_dir = '/kaggle/input/bonbid-2023-train/BONBID2023_Train/3LABEL'\n",
    "output_dir = '/kaggle/working/nifti_data'\n",
    "\n",
    "# Vytvoření výstupního adresáře\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Počet souborů v každém adresáři\n",
    "ph_count = len(glob(os.path.join(pseudo_healthy_dir, \"*.mha\")))\n",
    "adc_count = len(glob(os.path.join(adc_dir, \"*.mha\")))\n",
    "label_count = len(glob(os.path.join(label_dir, \"*.mha\")))\n",
    "\n",
    "print(f\"\\nPočty souborů: Pseudozdravé: {ph_count}, ADC: {adc_count}, Léze: {label_count}\")\n",
    "\n",
    "# Zkusíme přímější způsob párování - předpokládáme, že soubory mají konzistentní části názvů\n",
    "matched_data = []\n",
    "\n",
    "# Procházíme pseudozdravé soubory, jelikož jich máme nejméně\n",
    "for ph_file in sorted(glob(os.path.join(pseudo_healthy_dir, \"*.mha\"))):\n",
    "    ph_basename = os.path.basename(ph_file)\n",
    "    # Tady upravte regulární výraz podle skutečného formátu vašich souborů\n",
    "    match = re.search(r'(MGHNICU_\\d+-VISIT_\\d+)', ph_basename)\n",
    "    \n",
    "    if match:\n",
    "        pattern_id = match.group(1)\n",
    "        # Hledáme odpovídající ADC a léze soubory\n",
    "        adc_pattern = os.path.join(adc_dir, f\"{pattern_id}*ADC_ss.mha\")\n",
    "        lesion_pattern = os.path.join(label_dir, f\"{pattern_id}*lesion.mha\")\n",
    "        \n",
    "        adc_matches = glob(adc_pattern)\n",
    "        lesion_matches = glob(lesion_pattern)\n",
    "        \n",
    "        if adc_matches and lesion_matches:\n",
    "            # Konverze MHA na NIfTI\n",
    "            ph_nifti = convert_mha_to_nifti(ph_file, output_dir)\n",
    "            adc_nifti = convert_mha_to_nifti(adc_matches[0], output_dir)\n",
    "            lesion_nifti = convert_mha_to_nifti(lesion_matches[0], output_dir)\n",
    "            \n",
    "            matched_data.append({\n",
    "                'subject_id': pattern_id,\n",
    "                'pseudo_healthy': ph_nifti,\n",
    "                'adc': adc_nifti,\n",
    "                'lesion': lesion_nifti\n",
    "            })\n",
    "            print(f\"Nalezena shoda pro: {pattern_id}\")\n",
    "        else:\n",
    "            print(f\"Nenalezeny odpovídající soubory pro: {pattern_id}\")\n",
    "            if not adc_matches:\n",
    "                print(f\"  Žádné ADC soubory pro vzor: {adc_pattern}\")\n",
    "            if not lesion_matches:\n",
    "                print(f\"  Žádné léze soubory pro vzor: {lesion_pattern}\")\n",
    "\n",
    "# Pokud stále nemáme žádné shody, zkusíme flexibilnější párování\n",
    "if not matched_data:\n",
    "    # Pro každý pseudozdravý soubor\n",
    "    for ph_file in sorted(glob(os.path.join(pseudo_healthy_dir, \"*.mha\"))):\n",
    "        ph_basename = os.path.basename(ph_file)\n",
    "        \n",
    "        # Extrakt základního názvu bez přípony a specifických označení\n",
    "        base_name = ph_basename.replace('-PSEUDO_HEALTHY.mha', '').replace('_PSEUDO_HEALTHY.mha', '')\n",
    "        \n",
    "        # Hledání odpovídajících souborů podle základního názvu\n",
    "        for adc_file in sorted(glob(os.path.join(adc_dir, \"*.mha\"))):\n",
    "            adc_basename = os.path.basename(adc_file)\n",
    "            \n",
    "            # Kontrola, zda ADC soubor obsahuje základní název\n",
    "            if base_name in adc_basename:\n",
    "                # Hledání odpovídajícího léze souboru\n",
    "                for lesion_file in sorted(glob(os.path.join(label_dir, \"*.mha\"))):\n",
    "                    lesion_basename = os.path.basename(lesion_file)\n",
    "                    \n",
    "                    # Kontrola, zda léze soubor obsahuje základní název\n",
    "                    if base_name in lesion_basename:\n",
    "                        # Konverze MHA na NIfTI\n",
    "                        ph_nifti = convert_mha_to_nifti(ph_file, output_dir)\n",
    "                        adc_nifti = convert_mha_to_nifti(adc_file, output_dir)\n",
    "                        lesion_nifti = convert_mha_to_nifti(lesion_file, output_dir)\n",
    "                        \n",
    "                        matched_data.append({\n",
    "                            'subject_id': base_name,\n",
    "                            'pseudo_healthy': ph_nifti,\n",
    "                            'adc': adc_nifti,\n",
    "                            'lesion': lesion_nifti\n",
    "                        })\n",
    "                        break  # Po nalezení léze přejít na další ADC\n",
    "\n",
    "# Vytvoření CSV souboru\n",
    "df = pd.DataFrame(matched_data)\n",
    "csv_path = '/kaggle/working/brain2vec/inputs.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nVytvořen CSV soubor s {len(df)} záznamy: {csv_path}\")\n",
    "\n",
    "# Pokud stále nemáme žádné shody, vytvoříme testovací data\n",
    "if len(df) == 0:\n",
    "    print(\"\\nNebyly nalezeny žádné shody. Vytvářím umělá testovací data pro testování funkčnosti...\")\n",
    "    \n",
    "    # Vybereme několik souborů z každého adresáře pro testování\n",
    "    ph_files = sorted(glob(os.path.join(pseudo_healthy_dir, \"*.mha\")))[:3]\n",
    "    adc_files = sorted(glob(os.path.join(adc_dir, \"*.mha\")))[:3]\n",
    "    lesion_files = sorted(glob(os.path.join(label_dir, \"*.mha\")))[:3]\n",
    "    \n",
    "    if ph_files and adc_files and lesion_files:\n",
    "        test_data = []\n",
    "        \n",
    "        for i in range(min(len(ph_files), len(adc_files), len(lesion_files))):\n",
    "            # Konverze MHA na NIfTI\n",
    "            ph_nifti = convert_mha_to_nifti(ph_files[i], output_dir)\n",
    "            adc_nifti = convert_mha_to_nifti(adc_files[i], output_dir)\n",
    "            lesion_nifti = convert_mha_to_nifti(lesion_files[i], output_dir)\n",
    "            \n",
    "            test_data.append({\n",
    "                'subject_id': f'test_subject_{i}',\n",
    "                'pseudo_healthy': ph_nifti,\n",
    "                'adc': adc_nifti,\n",
    "                'lesion': lesion_nifti\n",
    "            })\n",
    "        \n",
    "        # Vytvoření CSV souboru s testovacími daty\n",
    "        test_df = pd.DataFrame(test_data)\n",
    "        test_csv_path = '/kaggle/working/brain2vec/inputs.csv'\n",
    "        test_df.to_csv(test_csv_path, index=False)\n",
    "        print(f\"Vytvořen testovací CSV soubor s {len(test_df)} záznamy: {test_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/brain2vec/finetune_hie_lesions.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from itertools import product\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from generative.networks.nets import AutoencoderKL\n",
    "import torch.serialization\n",
    "from numpy.core.multiarray import _reconstruct\n",
    "from numpy import ndarray, dtype\n",
    "from monai.data.meta_tensor import MetaTensor\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.ndimage import gaussian_filter, binary_dilation\n",
    "from scipy.ndimage import rotate, shift\n",
    "\n",
    "# Přidáváme bezpečné globály pro deserializaci objektů z PyTorch\n",
    "torch.serialization.add_safe_globals([_reconstruct])\n",
    "torch.serialization.add_safe_globals([MetaTensor])\n",
    "torch.serialization.add_safe_globals([ndarray])\n",
    "torch.serialization.add_safe_globals([dtype])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "class VGG19FeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_layers=None, use_cuda=True):\n",
    "        super(VGG19FeatureExtractor, self).__init__()\n",
    "        if feature_layers is None:\n",
    "            feature_layers = [2, 7, 12, 21, 30]  # Conv1_2, Conv2_2, Conv3_2, Conv4_2, Conv5_2\n",
    "        \n",
    "        self.feature_layers = feature_layers\n",
    "        \n",
    "        # Načtení předtrénované VGG19\n",
    "        vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "        self.vgg_features = vgg.features\n",
    "        \n",
    "        # Zmrazení vah\n",
    "        for param in self.vgg_features.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Převod na CUDA, pokud je dostupné\n",
    "        self.device = torch.device('cuda' if use_cuda and torch.cuda.is_available() else 'cpu')\n",
    "        self.vgg_features = self.vgg_features.to(self.device)\n",
    "        \n",
    "    def forward(self, x, slice_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Vstupní tensor tvaru [B, C, D, H, W] nebo [B, C, H, W]\n",
    "            slice_idx: Index řezu, pokud je vstup 3D. Pokud None, použije se prostřední řez.\n",
    "        \"\"\"\n",
    "        # Převeďme na 2D, pokud je vstup 3D\n",
    "        if x.dim() == 5:  # [B, C, D, H, W]\n",
    "            if slice_idx is None:\n",
    "                # Použití prostředního řezu\n",
    "                slice_idx = x.shape[2] // 2\n",
    "            x = x[:, :, slice_idx, :, :]  # [B, C, H, W]\n",
    "        \n",
    "        # VGG očekává 3 kanály (RGB)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "        \n",
    "        # Standardizace vstupu do VGG\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(x.device)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(x.device)\n",
    "        x = (x - mean) / std\n",
    "        \n",
    "        features = []\n",
    "        for i, layer in enumerate(self.vgg_features):\n",
    "            x = layer(x)\n",
    "            if i in self.feature_layers:\n",
    "                features.append(x)\n",
    "                \n",
    "        return features\n",
    "\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self, weights=None, use_cuda=True):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        if weights is None:\n",
    "            # Váhy pro různé vrstvy - můžete je upravit podle potřeby\n",
    "            weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.extractor = VGG19FeatureExtractor(use_cuda=use_cuda)\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, predicted, target, slice_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predicted: Predikovaný obraz [B, 1, D, H, W] nebo [B, 1, H, W]\n",
    "            target: Cílový obraz [B, 1, D, H, W] nebo [B, 1, H, W]\n",
    "            slice_idx: Index řezu, pokud jsou vstupy 3D. Pokud None, použije se prostřední řez.\n",
    "        \"\"\"\n",
    "        # Převod do rozsahu [0, 1] pokud jsou v jiném rozsahu\n",
    "        if predicted.max() > 1 or predicted.min() < 0:\n",
    "            predicted = (predicted - predicted.min()) / (predicted.max() - predicted.min() + 1e-7)\n",
    "        if target.max() > 1 or target.min() < 0:\n",
    "            target = (target - target.min()) / (target.max() - target.min() + 1e-7)\n",
    "        \n",
    "        pred_features = self.extractor(predicted, slice_idx)\n",
    "        target_features = self.extractor(target, slice_idx)\n",
    "        \n",
    "        loss = 0.0\n",
    "        for i in range(len(pred_features)):\n",
    "            loss += self.weights[i] * self.mse(pred_features[i], target_features[i])\n",
    "            \n",
    "        return loss\n",
    "\n",
    "# Adaptér pro 3D data, který aplikuje perceptual loss na několik řezů\n",
    "class PerceptualLoss3D(nn.Module):\n",
    "    def __init__(self, num_slices=3, weights=None, use_cuda=True):\n",
    "        super(PerceptualLoss3D, self).__init__()\n",
    "        self.perceptual_loss = PerceptualLoss(weights, use_cuda)\n",
    "        self.num_slices = num_slices\n",
    "        \n",
    "    def forward(self, predicted, target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predicted: Predikovaný 3D obraz [B, 1, D, H, W]\n",
    "            target: Cílový 3D obraz [B, 1, D, H, W]\n",
    "        \"\"\"\n",
    "        depth = predicted.shape[2]\n",
    "        if self.num_slices >= depth:\n",
    "            # Použij všechny řezy, pokud je jich méně než num_slices\n",
    "            slice_indices = list(range(depth))\n",
    "        else:\n",
    "            # Jinak vybírej rovnoměrně rozložené řezy\n",
    "            slice_indices = [int(i * (depth-1) / (self.num_slices-1)) for i in range(self.num_slices)]\n",
    "        \n",
    "        loss = 0.0\n",
    "        for idx in slice_indices:\n",
    "            loss += self.perceptual_loss(predicted, target, idx)\n",
    "            \n",
    "        return loss / len(slice_indices)\n",
    "\n",
    "class BrainLesionAugmentation:\n",
    "    def __init__(self, \n",
    "                 rotation_range=(-10, 10),     # rozsah náhodných rotací ve stupních\n",
    "                 flip_probability=0.5,         # pravděpodobnost překlápění\n",
    "                 intensity_shift_range=(-0.1, 0.1),  # posun intenzity\n",
    "                 intensity_scale_range=(0.9, 1.1),   # škálování intenzity\n",
    "                 noise_level=0.03):            # úroveň gaussovského šumu\n",
    "        \n",
    "        self.rotation_range = rotation_range\n",
    "        self.flip_probability = flip_probability\n",
    "        self.intensity_shift_range = intensity_shift_range\n",
    "        self.intensity_scale_range = intensity_scale_range\n",
    "        self.noise_level = noise_level\n",
    "    \n",
    "    def apply_augmentation(self, input_tensor, target_tensor, mask_tensor):\n",
    "        \"\"\"\n",
    "        Aplikuje stejné augmentace na vstupní tensor, cílový tensor a masku\n",
    "        \n",
    "        Args:\n",
    "            input_tensor: Tensor vstupního obrazu (pseudo-healthy) [C, D, H, W]\n",
    "            target_tensor: Tensor cílového obrazu (ADC s lézemi) [C, D, H, W]\n",
    "            mask_tensor: Tensor masky léze [C, D, H, W]\n",
    "            \n",
    "        Returns:\n",
    "            Augmentované tensory (input, target, mask)\n",
    "        \"\"\"\n",
    "        # Ověření, že všechny tensory mají stejný tvar\n",
    "        assert input_tensor.shape == target_tensor.shape == mask_tensor.shape\n",
    "        \n",
    "        device = input_tensor.device\n",
    "        \n",
    "        # Převedeme na numpy pro snazší manipulaci\n",
    "        input_np = input_tensor.cpu().numpy()\n",
    "        target_np = target_tensor.cpu().numpy()\n",
    "        mask_np = mask_tensor.cpu().numpy()\n",
    "        \n",
    "        # 1. Náhodné rotace\n",
    "        if self.rotation_range[0] < self.rotation_range[1]:\n",
    "            # Vybereme náhodný úhel z rozsahu\n",
    "            angle_x = np.random.uniform(*self.rotation_range)\n",
    "            angle_y = np.random.uniform(*self.rotation_range)\n",
    "            angle_z = np.random.uniform(*self.rotation_range)\n",
    "            \n",
    "            # Aplikujeme rotaci na všechny kanály\n",
    "            for c in range(input_np.shape[0]):\n",
    "                # Rotace kolem osy x\n",
    "                if abs(angle_x) > 1:\n",
    "                    input_np[c] = self._rotate_volume(input_np[c], angle_x, axis=0)\n",
    "                    target_np[c] = self._rotate_volume(target_np[c], angle_x, axis=0)\n",
    "                    mask_np[c] = self._rotate_volume(mask_np[c], angle_x, axis=0)\n",
    "                \n",
    "                # Rotace kolem osy y\n",
    "                if abs(angle_y) > 1:\n",
    "                    input_np[c] = self._rotate_volume(input_np[c], angle_y, axis=1)\n",
    "                    target_np[c] = self._rotate_volume(target_np[c], angle_y, axis=1)\n",
    "                    mask_np[c] = self._rotate_volume(mask_np[c], angle_y, axis=1)\n",
    "                \n",
    "                # Rotace kolem osy z\n",
    "                if abs(angle_z) > 1:\n",
    "                    input_np[c] = self._rotate_volume(input_np[c], angle_z, axis=2)\n",
    "                    target_np[c] = self._rotate_volume(target_np[c], angle_z, axis=2)\n",
    "                    mask_np[c] = self._rotate_volume(mask_np[c], angle_z, axis=2)\n",
    "        \n",
    "        # 2. Náhodné překlápění (flip)\n",
    "        if np.random.random() < self.flip_probability:\n",
    "            axis = np.random.choice([0, 1, 2])  # Náhodně vybereme osu\n",
    "            input_np = np.flip(input_np, axis=axis+1)  # +1 protože první dimenze je kanál\n",
    "            target_np = np.flip(target_np, axis=axis+1)\n",
    "            mask_np = np.flip(mask_np, axis=axis+1)\n",
    "        \n",
    "        # 3. Úpravy intenzity (pouze pro input a target, ne pro masku)\n",
    "        # Škálování intenzity\n",
    "        if self.intensity_scale_range[0] < self.intensity_scale_range[1]:\n",
    "            scale = np.random.uniform(*self.intensity_scale_range)\n",
    "            input_np = input_np * scale\n",
    "            target_np = target_np * scale\n",
    "            \n",
    "            # Oříznutí hodnot do platného rozsahu\n",
    "            input_np = np.clip(input_np, 0, 1)\n",
    "            target_np = np.clip(target_np, 0, 1)\n",
    "        \n",
    "        # Posun intenzity\n",
    "        if self.intensity_shift_range[0] < self.intensity_shift_range[1]:\n",
    "            shift = np.random.uniform(*self.intensity_shift_range)\n",
    "            input_np = input_np + shift\n",
    "            target_np = target_np + shift\n",
    "            \n",
    "            # Oříznutí hodnot do platného rozsahu\n",
    "            input_np = np.clip(input_np, 0, 1)\n",
    "            target_np = np.clip(target_np, 0, 1)\n",
    "        \n",
    "        # 4. Přidání Gaussovského šumu (pouze pro input, ne pro target nebo masku)\n",
    "        if self.noise_level > 0:\n",
    "            noise = np.random.normal(0, self.noise_level, input_np.shape)\n",
    "            input_np = input_np + noise\n",
    "            input_np = np.clip(input_np, 0, 1)\n",
    "        \n",
    "        # Převod zpět na tensory\n",
    "        input_tensor = torch.from_numpy(input_np).to(device)\n",
    "        target_tensor = torch.from_numpy(target_np).to(device)\n",
    "        # Zajistíme, že maska zůstane binární\n",
    "        mask_np = (mask_np > 0.5).astype(np.float32)\n",
    "        mask_tensor = torch.from_numpy(mask_np).to(device)\n",
    "        \n",
    "        return input_tensor, target_tensor, mask_tensor\n",
    "    \n",
    "    def _rotate_volume(self, volume, angle, axis=0):\n",
    "        \"\"\"\n",
    "        Rotuje 3D objem kolem dané osy\n",
    "        \n",
    "        Args:\n",
    "            volume: 3D numpy array\n",
    "            angle: Úhel rotace ve stupních\n",
    "            axis: Osa rotace (0=x, 1=y, 2=z)\n",
    "            \n",
    "        Returns:\n",
    "            Rotovaný objem\n",
    "        \"\"\"\n",
    "        from scipy.ndimage import rotate\n",
    "        \n",
    "        # Nerotujeme pokud je úhel příliš malý\n",
    "        if abs(angle) < 1:\n",
    "            return volume\n",
    "        \n",
    "        # Směr os v scipy.ndimage.rotate je jiný než v numpy array\n",
    "        axes_map = {\n",
    "            0: (1, 2),  # rotace kolem x -> rotace v rovině y-z\n",
    "            1: (0, 2),  # rotace kolem y -> rotace v rovině x-z\n",
    "            2: (0, 1),  # rotace kolem z -> rotace v rovině x-y\n",
    "        }\n",
    "        \n",
    "        # Aplikujeme rotaci pomocí scipy\n",
    "        rotated = rotate(volume, angle, axes=axes_map[axis], reshape=False, order=1, mode='nearest')\n",
    "        \n",
    "        return rotated\n",
    "\n",
    "class BrainLesionDataset(Dataset):\n",
    "    def __init__(self, csv_path, target_shape=(80, 96, 80), patch_overlap=0.5, augmentation=None, training=True):\n",
    "        \"\"\"\n",
    "        Dataset pro trénink patch-based modelu na lézích v mozku.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Cesta k CSV souboru s daty\n",
    "            target_shape: Cílový tvar patche (D, H, W)\n",
    "            patch_overlap: Překrytí mezi sousedními patchi pro zajištění kontinuity lézí (0-1)\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.target_shape = target_shape\n",
    "        self.patch_overlap = patch_overlap\n",
    "        self.augmentation = augmentation\n",
    "        self.training = training\n",
    "        \n",
    "        # Seznam všech patchů pro všechny subjekty\n",
    "        self.all_patches = []\n",
    "        \n",
    "        # Slovník mapující subjekt_id -> originální data a jejich tvary\n",
    "        self.subject_data = {}\n",
    "        \n",
    "        # Předpočítáme všechny patche pro všechny subjekty\n",
    "        print(\"Připravuji patche pro všechny subjekty...\")\n",
    "        for idx, row in self.data.iterrows():\n",
    "            subject_id = row['subject_id']\n",
    "            print(f\"Zpracovávám subjekt {subject_id} ({idx+1}/{len(self.data)})\")\n",
    "            \n",
    "            # Načteme originální data bez úprav\n",
    "            try:\n",
    "                ph_img = nib.load(row['pseudo_healthy'])\n",
    "                adc_img = nib.load(row['adc'])\n",
    "                lesion_img = nib.load(row['lesion'])\n",
    "                \n",
    "                # Ověříme, že mají všechny obrazy stejnou afinní matici a rozměry\n",
    "                if not np.allclose(ph_img.affine, adc_img.affine) or not np.allclose(ph_img.affine, lesion_img.affine):\n",
    "                    print(f\"  VAROVÁNÍ: Obrazy pro subjekt {subject_id} mají rozdílné afinní matice! Provádím resampling...\")\n",
    "                    \n",
    "                    # Použijeme afinní matici pseudo_healthy jako referenční\n",
    "                    ref_affine = ph_img.affine\n",
    "                    ref_shape = ph_img.shape\n",
    "                    \n",
    "                    # Resampling adc a lesion obrazů do prostoru referenčního obrazu\n",
    "                    # Pro ADC použijeme lineární interpolaci\n",
    "                    adc_data = np.array(adc_img.get_fdata())\n",
    "                    adc_data = np.clip(adc_data, 0, None)\n",
    "                    if adc_data.max() > 0: \n",
    "                        adc_data = adc_data / adc_data.max()\n",
    "                    \n",
    "                    # Pro masku léze použijeme nearest-neighbor interpolaci, aby zůstala binární\n",
    "                    lesion_data = np.array(lesion_img.get_fdata())\n",
    "                    lesion_data = (lesion_data > 0.1).astype(np.float32)\n",
    "                    \n",
    "                    # Pro převzorkování použijeme nibabel resample_to_img funkci, pokud je dostupná, jinak vlastní implementaci\n",
    "                    try:\n",
    "                        from nibabel.processing import resample_to_img\n",
    "                        \n",
    "                        # Resampling adc obrazu (lineární interpolace)\n",
    "                        new_adc_img = resample_to_img(adc_img, ph_img, interpolation='linear')\n",
    "                        adc_data = np.array(new_adc_img.get_fdata())\n",
    "                        \n",
    "                        # Resampling lesion obrazu (nearest neighbor, aby zůstal binární)\n",
    "                        new_lesion_img = resample_to_img(lesion_img, ph_img, interpolation='nearest')\n",
    "                        lesion_data = (np.array(new_lesion_img.get_fdata()) > 0.1).astype(np.float32)\n",
    "                        \n",
    "                    except (ImportError, AttributeError):\n",
    "                        print(\"  nibabel.processing.resample_to_img není dostupný, používám SciPy pro resampling...\")\n",
    "                        \n",
    "                        # Alternativní převzorkování pomocí scipy\n",
    "                        from scipy.ndimage import map_coordinates\n",
    "                        \n",
    "                        # Vytvoříme mřížku pro transformaci ze zdrojových do cílových souřadnic\n",
    "                        ijk_dest = np.mgrid[0:ref_shape[0], 0:ref_shape[1], 0:ref_shape[2]]\n",
    "                        ijk_dest = ijk_dest.reshape(3, -1)\n",
    "                        \n",
    "                        # Přidáme homogenní souřadnici\n",
    "                        ijk_dest_homog = np.vstack((ijk_dest, np.ones((1, ijk_dest.shape[1]))))\n",
    "                        \n",
    "                        # Transformace z cílových voxelových souřadnic do světa (mm)\n",
    "                        xyz_dest = ref_affine @ ijk_dest_homog\n",
    "                        \n",
    "                        # Transformace ze světa (mm) do zdrojových voxelových souřadnic\n",
    "                        ijk_src_adc = np.linalg.inv(adc_img.affine) @ xyz_dest\n",
    "                        ijk_src_lesion = np.linalg.inv(lesion_img.affine) @ xyz_dest\n",
    "                        \n",
    "                        # Převzorkování dat\n",
    "                        adc_data_resampled = np.zeros(ref_shape)\n",
    "                        lesion_data_resampled = np.zeros(ref_shape)\n",
    "                        \n",
    "                        # Trilineární interpolace pro ADC data\n",
    "                        map_coordinates(adc_data, ijk_src_adc[:3], output=adc_data_resampled.ravel(), order=1)\n",
    "                        \n",
    "                        # Nearest neighbor interpolace pro masku léze\n",
    "                        map_coordinates(lesion_data, ijk_src_lesion[:3], output=lesion_data_resampled.ravel(), order=0)\n",
    "                        \n",
    "                        adc_data = adc_data_resampled\n",
    "                        lesion_data = (lesion_data_resampled > 0.1).astype(np.float32)\n",
    "                    \n",
    "                    # Získáme data z pseudo_healthy\n",
    "                    ph_data = np.array(ph_img.get_fdata())\n",
    "                    if ph_data.max() > 0: \n",
    "                        ph_data = ph_data / ph_data.max()\n",
    "                    \n",
    "                else:\n",
    "                    # Pokud mají stejné afinní matice, použijeme data přímo\n",
    "                    ph_data = np.array(ph_img.get_fdata())\n",
    "                    adc_data = np.array(adc_img.get_fdata())\n",
    "                    lesion_data = np.array(lesion_img.get_fdata())\n",
    "                    \n",
    "                    # Normalizace (jen pro obrazová data)\n",
    "                    if ph_data.max() > 0: ph_data = ph_data / ph_data.max()\n",
    "                    if adc_data.max() > 0: adc_data = adc_data / adc_data.max()\n",
    "                    \n",
    "                    # Normalizace masek - ujistíme se, že jsou binární (0 nebo 1)\n",
    "                    lesion_data = (lesion_data > 0.1).astype(np.float32)\n",
    "                \n",
    "                if ph_img.shape != adc_img.shape or ph_img.shape != lesion_img.shape:\n",
    "                    print(f\"  VAROVÁNÍ: Obrazy pro subjekt {subject_id} mají rozdílné rozměry! Použiju rozměry z pseudo_healthy.\")\n",
    "                \n",
    "                # Uložíme originální data a jejich tvar do slovníku\n",
    "                self.subject_data[subject_id] = {\n",
    "                    'ph_data': ph_data,\n",
    "                    'adc_data': adc_data,\n",
    "                    'lesion_data': lesion_data,\n",
    "                    'orig_shape': ph_data.shape,\n",
    "                    'affine': ph_img.affine\n",
    "                }\n",
    "                \n",
    "                # Najdeme všechny léze a jejich centra\n",
    "                lesion_centers = self._find_all_lesion_centers(lesion_data)\n",
    "                \n",
    "                if not lesion_centers:\n",
    "                    print(f\"  Subjekt {subject_id}: Nenalezeny žádné léze, vytvářím patch ve středu objemu\")\n",
    "                    # Pokud nejsou léze, vytvoříme alespoň jeden patch ve středu objemu\n",
    "                    center = [d // 2 for d in lesion_data.shape]\n",
    "                    patch_info = {\n",
    "                        'subject_id': subject_id,\n",
    "                        'center': center,\n",
    "                        'has_lesion': False\n",
    "                    }\n",
    "                    self.all_patches.append(patch_info)\n",
    "                else:\n",
    "                    print(f\"  Subjekt {subject_id}: Nalezeno {len(lesion_centers)} center lézí\")\n",
    "                    \n",
    "                    # Pro každé centrum léze vytvoříme patch\n",
    "                    for i, center in enumerate(lesion_centers):\n",
    "                        patch_info = {\n",
    "                            'subject_id': subject_id,\n",
    "                            'center': center,\n",
    "                            'has_lesion': True\n",
    "                        }\n",
    "                        self.all_patches.append(patch_info)\n",
    "                    \n",
    "                    # Hledáme velké léze, které by mohly vyžadovat více patchů\n",
    "                    labeled_lesions, num_lesions = ndimage.label(lesion_data)\n",
    "                    \n",
    "                    for i in range(1, num_lesions + 1):\n",
    "                        lesion_mask = labeled_lesions == i\n",
    "                        lesion_size = np.sum(lesion_mask)\n",
    "                        \n",
    "                        # Pokud je léze větší než polovina velikosti patche, může vyžadovat více patchů\n",
    "                        if lesion_size > np.prod(self.target_shape) * 0.5:\n",
    "                            print(f\"  Subjekt {subject_id}: Léze {i} je velká ({lesion_size} voxelů), generuji dodatečné patche\")\n",
    "                            \n",
    "                            # ... zbytek kódu pro generování patchů zůstává stejný ...\n",
    "                            \n",
    "                            # Najdeme hranice léze\n",
    "                            indices = np.where(lesion_mask)\n",
    "                            min_bounds = [np.min(idx) for idx in indices]\n",
    "                            max_bounds = [np.max(idx) for idx in indices]\n",
    "                            \n",
    "                            # Vytvoříme mřížku bodů pro pokrytí léze\n",
    "                            # Stanovíme krok mezi patchi (s ohledem na překrytí)\n",
    "                            steps = [int(ts * (1 - self.patch_overlap)) for ts in self.target_shape]\n",
    "                            \n",
    "                            # Vypočítáme startovní pozice (rozšířené o polovinu patche na každou stranu)\n",
    "                            start_positions = []\n",
    "                            for dim, (min_b, max_b, step, ts) in enumerate(zip(min_bounds, max_bounds, steps, self.target_shape)):\n",
    "                                half_size = ts // 2\n",
    "                                start = max(0, min_b - half_size)\n",
    "                                end = min(lesion_data.shape[dim] - step, max_b + half_size)\n",
    "                                positions = list(range(start, end, step))\n",
    "                                if not positions or end > positions[-1]:\n",
    "                                    positions.append(min(end, lesion_data.shape[dim] - ts))\n",
    "                                start_positions.append(positions)\n",
    "                            \n",
    "                            # Vytvoříme všechny kombinace startovních pozic pro všechny dimenze\n",
    "                            for start_z, start_y, start_x in product(start_positions[0], start_positions[1], start_positions[2]):\n",
    "                                # Spočítáme střed patche\n",
    "                                center = [\n",
    "                                    start_z + self.target_shape[0] // 2,\n",
    "                                    start_y + self.target_shape[1] // 2,\n",
    "                                    start_x + self.target_shape[2] // 2\n",
    "                                ]\n",
    "                                \n",
    "                                # Kontrola, zda patch obsahuje alespoň část léze\n",
    "                                patch_mask = self._extract_patch(lesion_mask.astype(float), center)\n",
    "                                if np.sum(patch_mask) > 0:\n",
    "                                    patch_info = {\n",
    "                                        'subject_id': subject_id,\n",
    "                                        'center': center,\n",
    "                                        'has_lesion': True,\n",
    "                                        'patch_id': f\"lesion{i}_z{start_z}_y{start_y}_x{start_x}\"\n",
    "                                    }\n",
    "                                    # Přidáme pouze pokud podobný patch ještě neexistuje\n",
    "                                    if not any(self._is_similar_patch(p, patch_info) for p in self.all_patches):\n",
    "                                        self.all_patches.append(patch_info)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  CHYBA při zpracování subjektu {subject_id}: {e}\")\n",
    "        \n",
    "        print(f\"Celkem vytvořeno {len(self.all_patches)} patchů pro {len(self.data)} subjektů\")\n",
    "    \n",
    "    def _is_similar_patch(self, patch1, patch2, distance_threshold=20):\n",
    "        \"\"\"Kontroluje, zda jsou dva patche podobné (blízké centra)\"\"\"\n",
    "        if patch1['subject_id'] != patch2['subject_id']:\n",
    "            return False\n",
    "            \n",
    "        center1 = patch1['center']\n",
    "        center2 = patch2['center']\n",
    "        \n",
    "        # Vypočítáme euklidovskou vzdálenost mezi centry\n",
    "        distance = np.sqrt(sum((c1 - c2) ** 2 for c1, c2 in zip(center1, center2)))\n",
    "        return distance < distance_threshold\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_patches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Vrací konkrétní patch podle jeho indexu\"\"\"\n",
    "        patch_info = self.all_patches[idx]\n",
    "        subject_id = patch_info['subject_id']\n",
    "        center = patch_info['center']\n",
    "        \n",
    "        # Získáme data subjektu ze slovníku\n",
    "        subject_data = self.subject_data[subject_id]\n",
    "        \n",
    "        # Vytvoříme výřez (patch) se středem v lézi\n",
    "        ph_patch = self._extract_patch(subject_data['ph_data'], center)\n",
    "        adc_patch = self._extract_patch(subject_data['adc_data'], center)\n",
    "        lesion_patch = self._extract_patch(subject_data['lesion_data'], center)\n",
    "        \n",
    "        # Převod na tensory a přidání dimenze pro kanál\n",
    "        ph_tensor = torch.from_numpy(ph_patch).float().unsqueeze(0)\n",
    "        adc_tensor = torch.from_numpy(adc_patch).float().unsqueeze(0)\n",
    "        lesion_tensor = torch.from_numpy(lesion_patch).float().unsqueeze(0)\n",
    "        \n",
    "        if self.augmentation is not None and self.training:\n",
    "            ph_tensor, adc_tensor, lesion_tensor = self.augmentation.apply_augmentation(\n",
    "                ph_tensor, adc_tensor, lesion_tensor\n",
    "            )\n",
    "        ph_tensor = ph_tensor.float()\n",
    "        adc_tensor = adc_tensor.float()\n",
    "        lesion_tensor = lesion_tensor.float()\n",
    "        \n",
    "        # Připravíme metadata o patchi pro zpětnou rekonstrukci\n",
    "        patch_meta = {\n",
    "            'subject_id': subject_id,\n",
    "            'center': center,\n",
    "            'patch_id': patch_info.get('patch_id', f\"patch_{idx}\"),\n",
    "            'has_lesion': patch_info['has_lesion'],\n",
    "            'orig_shape': subject_data['orig_shape'],\n",
    "            'patch_shape': self.target_shape\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'input': ph_tensor,\n",
    "            'target': adc_tensor,\n",
    "            'mask': lesion_tensor,\n",
    "            'subject_id': subject_id,\n",
    "            'patch_meta': patch_meta\n",
    "        }\n",
    "    \n",
    "    def _find_all_lesion_centers(self, mask):\n",
    "        \"\"\"Najde centra všech souvislých lézí v masce\"\"\"\n",
    "        # Pokud maska neobsahuje léze, vrátíme prázdný seznam\n",
    "        if np.max(mask) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Označíme souvislé oblasti v binární masce\n",
    "        binary_mask = mask > 0.1\n",
    "        labeled_mask, num_features = ndimage.label(binary_mask)\n",
    "        \n",
    "        centers = []\n",
    "        # Pro každou souvislou oblast najdeme centrum\n",
    "        for i in range(1, num_features + 1):\n",
    "            region_mask = labeled_mask == i\n",
    "            if np.sum(region_mask) > 10:  # Ignorujeme velmi malé léze (méně než 10 voxelů)\n",
    "                center = ndimage.center_of_mass(region_mask)\n",
    "                centers.append([int(c) for c in center])\n",
    "        \n",
    "        return centers\n",
    "    \n",
    "    def _extract_patch(self, data, center, padding_value=0):\n",
    "        \"\"\"Extrahuje patch pevné velikosti ze zadaných dat kolem zadaného centra bez interpolace\"\"\"\n",
    "        # Převedeme centrum na integer indexy\n",
    "        center = [int(c) for c in center]\n",
    "        \n",
    "        # Vytvoříme prázdný patch cílové velikosti\n",
    "        patch = np.ones(self.target_shape, dtype=np.float32) * padding_value\n",
    "        \n",
    "        # Pro každou dimenzi vypočítáme hranice výřezu\n",
    "        data_starts = []  # Startovní indexy v původních datech\n",
    "        data_ends = []    # Koncové indexy v původních datech\n",
    "        patch_starts = [] # Startovní indexy v patchi\n",
    "        patch_ends = []   # Koncové indexy v patchi\n",
    "        \n",
    "        for dim, (center_pos, target_size, data_size) in enumerate(zip(center, self.target_shape, data.shape)):\n",
    "            # Polovina velikosti cílového tvaru pro danou dimenzi\n",
    "            half_size = target_size // 2\n",
    "            \n",
    "            # Výpočet hranic v původních datech\n",
    "            data_start = max(0, center_pos - half_size)\n",
    "            data_end = min(data_size, center_pos + half_size + (target_size % 2))\n",
    "            \n",
    "            # Výpočet odpovídajících hranic v patchi\n",
    "            patch_start = max(0, half_size - center_pos)\n",
    "            patch_end = patch_start + (data_end - data_start)\n",
    "            \n",
    "            data_starts.append(data_start)\n",
    "            data_ends.append(data_end)\n",
    "            patch_starts.append(patch_start)\n",
    "            patch_ends.append(patch_end)\n",
    "        \n",
    "        # Zkopírujeme data z původního obrazu do patche BEZ INTERPOLACE\n",
    "        patch[patch_starts[0]:patch_ends[0], \n",
    "              patch_starts[1]:patch_ends[1], \n",
    "              patch_starts[2]:patch_ends[2]] = data[data_starts[0]:data_ends[0], \n",
    "                                                   data_starts[1]:data_ends[1], \n",
    "                                                   data_starts[2]:data_ends[2]]\n",
    "        \n",
    "        return patch\n",
    "    \n",
    "    def get_full_subject_data(self, subject_id):\n",
    "        \"\"\"Vrátí originální data pro daný subjekt\"\"\"\n",
    "        return self.subject_data.get(subject_id, None)\n",
    "    \n",
    "    def get_patch_locations(self, subject_id):\n",
    "        \"\"\"Vrátí seznam všech patch lokací pro daný subjekt\"\"\"\n",
    "        return [p for p in self.all_patches if p['subject_id'] == subject_id]\n",
    "    \n",
    "    def reconstruct_full_volume(self, patches, patch_centers, orig_shape, blend_weights=True):\n",
    "        \"\"\"\n",
    "        Rekonstruuje plný objem z patchů.\n",
    "        \n",
    "        Args:\n",
    "            patches: Seznam patchů (numpy arrays)\n",
    "            patch_centers: Seznam center patchů v původním objemu\n",
    "            orig_shape: Tvar původního objemu\n",
    "            blend_weights: Zda použít vážené průměrování pro překrývající se oblasti\n",
    "            \n",
    "        Returns:\n",
    "            Rekonstruovaný objem\n",
    "        \"\"\"\n",
    "        # Inicializujeme prázdný výstupní objem a váhový objem pro vážené průměrování\n",
    "        output_volume = np.zeros(orig_shape, dtype=np.float32)\n",
    "        weight_volume = np.zeros(orig_shape, dtype=np.float32)\n",
    "        \n",
    "        # Pro každý patch\n",
    "        for patch, center in zip(patches, patch_centers):\n",
    "            # Vytvoříme váhovou masku pro tento patch\n",
    "            if blend_weights:\n",
    "                # Vytvořím Gaussovskou váhu, vyšší ve středu patche a nižší na okrajích\n",
    "                weight_mask = np.ones(self.target_shape, dtype=np.float32)\n",
    "                \n",
    "                # Pro každou dimenzi vytvoříme gaussovský profil\n",
    "                for dim in range(3):\n",
    "                    # Vytvoříme souřadnicovou síť pro danou dimenzi\n",
    "                    coords = np.linspace(-1, 1, self.target_shape[dim])\n",
    "                    \n",
    "                    # Gaussovský profil: exp(-x^2/sigma^2)\n",
    "                    sigma = 0.4  # Šířka gaussovské křivky\n",
    "                    gauss_profile = np.exp(-(coords**2) / (2 * sigma**2))\n",
    "                    \n",
    "                    # Rozšíříme profil do správného tvaru pro násobení\n",
    "                    if dim == 0:\n",
    "                        gauss_profile = gauss_profile.reshape(-1, 1, 1)\n",
    "                    elif dim == 1:\n",
    "                        gauss_profile = gauss_profile.reshape(1, -1, 1)\n",
    "                    else:\n",
    "                        gauss_profile = gauss_profile.reshape(1, 1, -1)\n",
    "                    \n",
    "                    # Vynásobíme aktuální váhovou masku gaussovským profilem\n",
    "                    weight_mask = weight_mask * gauss_profile\n",
    "                \n",
    "                # Normalizace vah na rozsah 0-1\n",
    "                weight_mask = weight_mask / np.max(weight_mask)\n",
    "            else:\n",
    "                # Jednotná váha pro celý patch\n",
    "                weight_mask = np.ones(self.target_shape, dtype=np.float32)\n",
    "            \n",
    "            # Vypočítáme hranice pro vložení patche do původního objemu\n",
    "            data_starts = []\n",
    "            data_ends = []\n",
    "            patch_starts = []\n",
    "            patch_ends = []\n",
    "            \n",
    "            for dim, (center_pos, target_size) in enumerate(zip(center, self.target_shape)):\n",
    "                half_size = target_size // 2\n",
    "                \n",
    "                # Výpočet hranic v původním objemu\n",
    "                data_start = max(0, center_pos - half_size)\n",
    "                data_end = min(orig_shape[dim], center_pos + half_size + (target_size % 2))\n",
    "                \n",
    "                # Výpočet odpovídajících hranic v patchi\n",
    "                patch_start = max(0, half_size - center_pos)\n",
    "                patch_end = patch_start + (data_end - data_start)\n",
    "                \n",
    "                data_starts.append(data_start)\n",
    "                data_ends.append(data_end)\n",
    "                patch_starts.append(patch_start)\n",
    "                patch_ends.append(patch_end)\n",
    "            \n",
    "            # Přidáme vážený patch do výstupního objemu\n",
    "            output_volume[data_starts[0]:data_ends[0], \n",
    "                          data_starts[1]:data_ends[1], \n",
    "                          data_starts[2]:data_ends[2]] += \\\n",
    "                patch[patch_starts[0]:patch_ends[0], \n",
    "                      patch_starts[1]:patch_ends[1], \n",
    "                      patch_starts[2]:patch_ends[2]] * \\\n",
    "                weight_mask[patch_starts[0]:patch_ends[0], \n",
    "                           patch_starts[1]:patch_ends[1], \n",
    "                           patch_starts[2]:patch_ends[2]]\n",
    "            \n",
    "            # Přidáme váhy do váhového objemu\n",
    "            weight_volume[data_starts[0]:data_ends[0], \n",
    "                          data_starts[1]:data_ends[1], \n",
    "                          data_starts[2]:data_ends[2]] += \\\n",
    "                weight_mask[patch_starts[0]:patch_ends[0], \n",
    "                           patch_starts[1]:patch_ends[1], \n",
    "                           patch_starts[2]:patch_ends[2]]\n",
    "        \n",
    "        # Normalizujeme výstupní objem váhami (vyhneme se dělení nulou)\n",
    "        valid_mask = weight_volume > 0\n",
    "        output_volume[valid_mask] = output_volume[valid_mask] / weight_volume[valid_mask]\n",
    "        \n",
    "        return output_volume\n",
    "\n",
    "def weighted_lesion_loss(outputs, targets, masks, lesion_weight=10.0):\n",
    "    \"\"\"\n",
    "    Váhovaná loss funkce, která klade větší důraz na oblasti lézí.\n",
    "    \n",
    "    Args:\n",
    "        outputs: Výstupy modelu\n",
    "        targets: Cílové hodnoty\n",
    "        masks: Binární masky lézí\n",
    "        lesion_weight: Váha aplikovaná na oblasti lézí (1.0 znamená žádné převážení)\n",
    "        \n",
    "    Returns:\n",
    "        Celková loss\n",
    "    \"\"\"\n",
    "    # Základní L1 loss pro celý obraz\n",
    "    base_loss = torch.abs(outputs - targets)\n",
    "    \n",
    "    # Vytvoříme váhovou mapu: 1.0 pro zdravé oblasti, lesion_weight pro oblasti lézí\n",
    "    weight_map = 1.0 + (lesion_weight - 1.0) * masks\n",
    "    \n",
    "    # Aplikujeme váhovou mapu na loss\n",
    "    weighted_loss = base_loss * weight_map\n",
    "    \n",
    "    # Vrátíme průměr\n",
    "    return weighted_loss.mean()\n",
    "\n",
    "# Funkce pro vyhlazení výstupu jako post-processing\n",
    "def apply_smoothing(outputs, masks, inputs, sigma=0.8, iterations=2):\n",
    "    \"\"\"\n",
    "    Aplikuje gaussovské vyhlazení pouze na okolí léze, ale ne na lézi samotnou.\n",
    "    Zachovává strukturu léze a vytváří plynulý přechod na hranicích.\n",
    "    \n",
    "    Args:\n",
    "        outputs: Tensor výstupu modelu ve tvaru (B, 1, D, H, W)\n",
    "        masks: Tensor masek lézí ve tvaru (B, 1, D, H, W)\n",
    "        inputs: Tensor vstupů ve tvaru (B, 1, D, H, W) - použijeme pro vytvoření masky mozku\n",
    "        sigma: Parametr rozptylu pro Gaussovské vyhlazení\n",
    "        iterations: Počet iterací dilatace pro okolí léze\n",
    "    \n",
    "    Returns:\n",
    "        Tensor upraveného výstupu se stejným tvarem jako vstup\n",
    "    \"\"\"\n",
    "    smoothed_results = []\n",
    "    \n",
    "    # Převod na numpy pro efektivnější zpracování\n",
    "    outputs_np = outputs.detach().cpu().numpy()\n",
    "    masks_np = masks.detach().cpu().numpy()\n",
    "    inputs_np = inputs.detach().cpu().numpy()\n",
    "    \n",
    "    for b in range(outputs.shape[0]):\n",
    "        # Získání dat pro aktuální batch\n",
    "        curr_output = outputs_np[b, 0]\n",
    "        curr_mask = masks_np[b, 0]\n",
    "        curr_input = inputs_np[b, 0]\n",
    "        \n",
    "        # Vytvoření binární masky mozku - všude, kde je nenulová hodnota vstupu\n",
    "        brain_mask = (curr_input > 0.01).astype(np.float32)\n",
    "        \n",
    "        # Vytvoření binární masky léze\n",
    "        lesion_mask = (curr_mask > 0.1).astype(np.float32)\n",
    "        \n",
    "        # Vytvoření dilatované masky pro okolí léze\n",
    "        dilated_mask = binary_dilation(lesion_mask, iterations=iterations).astype(np.float32)\n",
    "        \n",
    "        # Vytvoření masky pouze pro okolí léze (dilatovaná oblast minus původní léze)\n",
    "        # Toto je klíčová změna - oddělíme okolí léze od samotné léze\n",
    "        transition_zone_mask = dilated_mask - lesion_mask\n",
    "        \n",
    "        # Zajistíme, že přechodová zóna zůstane uvnitř masky mozku\n",
    "        transition_zone_mask = transition_zone_mask * brain_mask\n",
    "        \n",
    "        # Aplikace gaussovského vyhlazení na celý výstup\n",
    "        smoothed = gaussian_filter(curr_output, sigma=sigma)\n",
    "        \n",
    "        # Zajistíme, že vyhlazený výstup zůstane uvnitř masky mozku\n",
    "        smoothed = smoothed * brain_mask\n",
    "        \n",
    "        # Kombinace:\n",
    "        # 1. Původní výstup v místech mimo přechodovou zónu (včetně lézí)\n",
    "        # 2. Vyhlazený výstup v přechodové zóně\n",
    "        final_output = curr_output * (1 - transition_zone_mask) + smoothed * transition_zone_mask\n",
    "        \n",
    "        # Převod zpět na tensor\n",
    "        smoothed_results.append(torch.from_numpy(final_output).to(outputs.device))\n",
    "    \n",
    "    # Složení výsledného batch tensoru\n",
    "    result = torch.stack(smoothed_results).unsqueeze(1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_lesion_metrics(outputs, targets, masks, inputs=None):\n",
    "    \"\"\"\n",
    "    Vypočítá metriky zaměřené specificky na kvalitu rekonstrukce lézí.\n",
    "    \n",
    "    Args:\n",
    "        outputs: Výstupy modelu\n",
    "        targets: Cílové ADC mapy\n",
    "        masks: Binární masky lézí\n",
    "        inputs: Původní pseudozdravý obraz (volitelný)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary s metrikami pro léze\n",
    "    \"\"\"\n",
    "    # Převod na numpy pro výpočet\n",
    "    outputs_np = outputs.detach().cpu().numpy()\n",
    "    targets_np = targets.detach().cpu().numpy()\n",
    "    masks_np = masks.detach().cpu().numpy() > 0.5\n",
    "    \n",
    "    # Pokud nemáme žádné léze, vrátíme prázdný slovník\n",
    "    if np.sum(masks_np) == 0:\n",
    "        if inputs is None:\n",
    "            return {'lesion_mae': 0.0}\n",
    "        else:\n",
    "            return {'lesion_mae': 0.0, 'input_output_lesion_mae': 0.0}\n",
    "    \n",
    "    # MAE pouze pro oblasti lézí (výstup vs. cíl)\n",
    "    lesion_mae = np.sum(np.abs(outputs_np[masks_np] - targets_np[masks_np])) / np.sum(masks_np)\n",
    "    \n",
    "    # Pokud máme k dispozici původní vstupy, počítáme také MAE mezi vstupem a výstupem v oblasti léze\n",
    "    if inputs is not None:\n",
    "        inputs_np = inputs.detach().cpu().numpy()\n",
    "        input_output_lesion_mae = np.sum(np.abs(outputs_np[masks_np] - inputs_np[masks_np])) / np.sum(masks_np)\n",
    "        return {'lesion_mae': float(lesion_mae), 'input_output_lesion_mae': float(input_output_lesion_mae)}\n",
    "    \n",
    "    return {'lesion_mae': float(lesion_mae)}\n",
    "\n",
    "class HIELesionInpainter(nn.Module):\n",
    "    def __init__(self, checkpoint_path, device=\"cpu\"):\n",
    "        super(HIELesionInpainter, self).__init__()\n",
    "        \n",
    "        # Vytvoření modelu s přesně stejnou architekturou jako brain2vec\n",
    "        self.vae = AutoencoderKL(\n",
    "            spatial_dims=3, \n",
    "            in_channels=1, \n",
    "            out_channels=1, \n",
    "            latent_channels=1,\n",
    "            num_channels=(64, 128, 128, 128),\n",
    "            num_res_blocks=2, \n",
    "            norm_num_groups=32,\n",
    "            norm_eps=1e-06,\n",
    "            attention_levels=(False, False, False, False), \n",
    "            with_decoder_nonlocal_attn=False, \n",
    "            with_encoder_nonlocal_attn=False\n",
    "        )\n",
    "        \n",
    "        print(f\"Načítání checkpoint z: {checkpoint_path}\")\n",
    "        try:\n",
    "            # Načtení vah z checkpointu brain2vec\n",
    "            state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "            \n",
    "            # Zobrazíme informace o načteném state_dict\n",
    "            sample_keys = list(state_dict.keys())[:5]\n",
    "            \n",
    "            # Pokus o načtení vah\n",
    "            missing, unexpected = self.vae.load_state_dict(state_dict, strict=False)\n",
    "            print(f\"Načítání vah - chybějící klíče: {len(missing)}, neočekávané klíče: {len(unexpected)}\")\n",
    "            if len(missing) > 0:\n",
    "                print(f\"Příklady chybějících klíčů: {missing[:3]}\")\n",
    "            if len(unexpected) > 0:\n",
    "                print(f\"Příklady neočekávaných klíčů: {unexpected[:3]}\")\n",
    "            \n",
    "            print(\"Váhy částečně načteny s tolerancí k rozdílům v architektuře\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Chyba při načítání vah: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"Pokračuji s náhodně inicializovanými vahami\")\n",
    "        \n",
    "        # Zmrazíme encoder pro fine-tuning\n",
    "        for name, param in self.vae.named_parameters():\n",
    "            if \"encoder\" in name:\n",
    "                # Odmrazíme pouze poslední vrstvy enkodéru\n",
    "                # Hledáme vrstvy ve vzorech jako \"encoder.down.2\" nebo \"encoder.down.3\" nebo \"encoder.mid\"\n",
    "                if any(pattern in name for pattern in [\"encoder.down.2\", \"encoder.down.3\", \"encoder.mid\"]):\n",
    "                    param.requires_grad = True\n",
    "                    print(f\"Odmrazena vrstva: {name}\")\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "                    \n",
    "        print(\"Encoder vrstvy částečně odmrazeny - poslední vrstvy jsou aktivní pro trénink\")\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        # Pokud jsme v trénovacím módu a používáme perceptuální ztrátu,\n",
    "        # potřebujeme gradienty z enkodéru\n",
    "        if self.training:\n",
    "            z_mu, z_sigma = self.vae.encode(x)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                z_mu, z_sigma = self.vae.encode(x)\n",
    "        \n",
    "        # Zbytek kódu zůstává stejný\n",
    "        decoded = self.vae.decode(z_mu)\n",
    "        if decoded.shape != x.shape:\n",
    "            decoded = F.interpolate(decoded, size=x.shape[2:], mode='trilinear', align_corners=False)\n",
    "        raw_output = x * (1 - mask) + decoded * mask\n",
    "        return raw_output\n",
    "\n",
    "# Funkce pro vyhlazení výstupu jako post-processing\n",
    "def apply_smoothing(outputs, masks, inputs, sigma=0.8, iterations=2):\n",
    "    \"\"\"\n",
    "    Aplikuje gaussovské vyhlazení pouze na okolí léze, ale ne na lézi samotnou.\n",
    "    Zachovává strukturu léze a vytváří plynulý přechod na hranicích.\n",
    "    \n",
    "    Args:\n",
    "        outputs: Tensor výstupu modelu ve tvaru (B, 1, D, H, W)\n",
    "        masks: Tensor masek lézí ve tvaru (B, 1, D, H, W)\n",
    "        inputs: Tensor vstupů ve tvaru (B, 1, D, H, W) - použijeme pro vytvoření masky mozku\n",
    "        sigma: Parametr rozptylu pro Gaussovské vyhlazení\n",
    "        iterations: Počet iterací dilatace pro okolí léze\n",
    "    \n",
    "    Returns:\n",
    "        Tensor upraveného výstupu se stejným tvarem jako vstup\n",
    "    \"\"\"\n",
    "    smoothed_results = []\n",
    "    \n",
    "    # Převod na numpy pro efektivnější zpracování\n",
    "    outputs_np = outputs.detach().cpu().numpy()\n",
    "    masks_np = masks.detach().cpu().numpy()\n",
    "    inputs_np = inputs.detach().cpu().numpy()\n",
    "    \n",
    "    for b in range(outputs.shape[0]):\n",
    "        # Získání dat pro aktuální batch\n",
    "        curr_output = outputs_np[b, 0]\n",
    "        curr_mask = masks_np[b, 0]\n",
    "        curr_input = inputs_np[b, 0]\n",
    "        \n",
    "        # Vytvoření binární masky mozku - všude, kde je nenulová hodnota vstupu\n",
    "        brain_mask = (curr_input > 0.01).astype(np.float32)\n",
    "        \n",
    "        # Vytvoření binární masky léze\n",
    "        lesion_mask = (curr_mask > 0.1).astype(np.float32)\n",
    "        \n",
    "        # Vytvoření dilatované masky pro okolí léze\n",
    "        dilated_mask = binary_dilation(lesion_mask, iterations=iterations).astype(np.float32)\n",
    "        \n",
    "        # Vytvoření masky pouze pro okolí léze (dilatovaná oblast minus původní léze)\n",
    "        # Toto je klíčová změna - oddělíme okolí léze od samotné léze\n",
    "        transition_zone_mask = dilated_mask - lesion_mask\n",
    "        \n",
    "        # Zajistíme, že přechodová zóna zůstane uvnitř masky mozku\n",
    "        transition_zone_mask = transition_zone_mask * brain_mask\n",
    "        \n",
    "        # Aplikace gaussovského vyhlazení na celý výstup\n",
    "        smoothed = gaussian_filter(curr_output, sigma=sigma)\n",
    "        \n",
    "        # Zajistíme, že vyhlazený výstup zůstane uvnitř masky mozku\n",
    "        smoothed = smoothed * brain_mask\n",
    "        \n",
    "        # Kombinace:\n",
    "        # 1. Původní výstup v místech mimo přechodovou zónu (včetně lézí)\n",
    "        # 2. Vyhlazený výstup v přechodové zóně\n",
    "        final_output = curr_output * (1 - transition_zone_mask) + smoothed * transition_zone_mask\n",
    "        \n",
    "        # Převod zpět na tensor\n",
    "        smoothed_results.append(torch.from_numpy(final_output).to(outputs.device))\n",
    "    \n",
    "    # Složení výsledného batch tensoru\n",
    "    result = torch.stack(smoothed_results).unsqueeze(1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def visualize_full_subject(dataset, model, subject_id, epoch, output_dir, device):\n",
    "    \"\"\"\n",
    "    Vytvoří a uloží vizualizace pro celý objem mozku jednoho subjektu.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Instance BrainLesionDataset\n",
    "        model: Natrénovaný model HIELesionInpainter\n",
    "        subject_id: ID subjektu pro vizualizaci\n",
    "        epoch: Číslo epochy\n",
    "        output_dir: Adresář pro uložení vizualizací\n",
    "        device: Zařízení pro běh modelu (CPU/GPU)\n",
    "    \"\"\"\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    \n",
    "    viz_dir = os.path.join(output_dir, 'visualizations')\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Vizualizuji celý subjekt {subject_id} pro epochu {epoch}...\")\n",
    "    \n",
    "    # Získám originální data subjektu\n",
    "    subject_data = dataset.get_full_subject_data(subject_id)\n",
    "    if subject_data is None:\n",
    "        print(f\"  VAROVÁNÍ: Data pro subjekt {subject_id} nenalezena!\")\n",
    "        return\n",
    "    \n",
    "    ph_data = subject_data['ph_data']\n",
    "    adc_data = subject_data['adc_data']\n",
    "    lesion_data = subject_data['lesion_data']\n",
    "    orig_shape = subject_data['orig_shape']\n",
    "    \n",
    "    # Získám všechny patche pro tento subjekt\n",
    "    patch_locations = dataset.get_patch_locations(subject_id)\n",
    "    \n",
    "    # Připravím patche pro rekonstrukci\n",
    "    output_patches = []\n",
    "    patch_centers = []\n",
    "    \n",
    "    # Pro každou lokaci patche\n",
    "    for patch_info in patch_locations:\n",
    "        center = patch_info['center']\n",
    "        \n",
    "        # Extrakce patche pro vstup do modelu\n",
    "        ph_patch = dataset._extract_patch(ph_data, center)\n",
    "        lesion_patch = dataset._extract_patch(lesion_data, center)\n",
    "        \n",
    "        # Převod na tensory\n",
    "        ph_tensor = torch.from_numpy(ph_patch).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "        lesion_tensor = torch.from_numpy(lesion_patch).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Inference modelu\n",
    "        with torch.no_grad():\n",
    "            raw_output = model(ph_tensor, lesion_tensor)\n",
    "            smooth_output = apply_smoothing(raw_output, lesion_tensor, ph_tensor)\n",
    "        \n",
    "        # Uložím výstupní patch a jeho centrum\n",
    "        output_patches.append(smooth_output[0, 0].cpu().numpy())\n",
    "        patch_centers.append(center)\n",
    "    \n",
    "    # Rekonstrukce plného objemu\n",
    "    reconstructed_output = dataset.reconstruct_full_volume(\n",
    "        output_patches, patch_centers, orig_shape, blend_weights=True\n",
    "    )\n",
    "    \n",
    "    # Najdeme všechny řezy, které obsahují léze\n",
    "    z_slices_with_lesions = np.where(np.any(lesion_data > 0.1, axis=(1, 2)))[0]\n",
    "    \n",
    "    # Pokud nemáme žádné léze, zobrazíme alespoň jeden řez ve středu objemu\n",
    "    if len(z_slices_with_lesions) == 0:\n",
    "        z_slices_with_lesions = [orig_shape[0] // 2]\n",
    "        print(f\"Subjekt {subject_id}: Nenalezeny žádné léze\")\n",
    "    else:\n",
    "        print(f\"Subjekt {subject_id}: Nalezeno {len(z_slices_with_lesions)} řezů s lézemi\")\n",
    "    \n",
    "    # Výpočet MAE pro celý objem s lézemi\n",
    "    mask_volume = lesion_data > 0.1\n",
    "    lesion_voxel_count = np.sum(mask_volume)\n",
    "    \n",
    "    # SOUBOR - PDF s detailními vizualizacemi všech řezů\n",
    "    pdf_filename = f'epoch_{epoch:03d}_subject_{subject_id}_all_slices.pdf'\n",
    "    pdf_path = os.path.join(viz_dir, pdf_filename)\n",
    "    \n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        # Nejprve vytvoříme souhrnnou stránku s informacemi\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.text(0.5, 0.5, \n",
    "                 f\"Vizualizace pro epochu {epoch}\\nSubjekt: {subject_id}\\n\"\n",
    "                 f\"Počet řezů s lézemi: {len(z_slices_with_lesions)}\\n\"\n",
    "                 f\"Celkový počet voxelů s lézí: {lesion_voxel_count}\\n\", \n",
    "                 ha='center', va='center', fontsize=16)\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        \n",
    "        # Pro každý řez s lézí vytvoříme vizualizaci\n",
    "        slice_mae_values = []\n",
    "        \n",
    "        for z_slice in z_slices_with_lesions:\n",
    "            # Vytvoříme figure se 4 subplot podle požadavků\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "            \n",
    "            # Normalizace pro lepší vizualizaci\n",
    "            norm = Normalize(vmin=0, vmax=1)\n",
    "            \n",
    "            # 1. Output modelu (vpravo nahoře)\n",
    "            im1 = axes[0, 1].imshow(reconstructed_output[z_slice], cmap='gray', norm=norm)\n",
    "            axes[0, 1].set_title('1. Výstup modelu (rekonstrukce)')\n",
    "            axes[0, 1].axis('off')\n",
    "            plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # 2. Target mapa (ADC s lézemi) (vpravo dole)\n",
    "            im2 = axes[1, 1].imshow(adc_data[z_slice], cmap='gray', norm=norm)\n",
    "            axes[1, 1].set_title('2. Target (ADC s lézemi)')\n",
    "            axes[1, 1].axis('off')\n",
    "            plt.colorbar(im2, ax=axes[1, 1], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # 3. Původní pseudozdravý obraz (vlevo nahoře)\n",
    "            im3 = axes[0, 0].imshow(ph_data[z_slice], cmap='gray', norm=norm)\n",
    "            axes[0, 0].set_title('3. Původní pseudozdravý obraz')\n",
    "            axes[0, 0].axis('off')\n",
    "            plt.colorbar(im3, ax=axes[0, 0], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # 4. Pseudozdravý obraz se zakreslenými lézemi (vlevo dole)\n",
    "            # Vytvoříme RGB obrázek s červeně vyznačenými lézemi\n",
    "            overlay = np.zeros((orig_shape[1], orig_shape[2], 3))\n",
    "            overlay[:, :, 0] = ph_data[z_slice]  # R kanál - vstup\n",
    "            overlay[:, :, 1] = ph_data[z_slice]  # G kanál - vstup\n",
    "            overlay[:, :, 2] = ph_data[z_slice]  # B kanál - vstup\n",
    "            \n",
    "            # Přidáme léze jako červené oblasti\n",
    "            mask_slice = lesion_data[z_slice]\n",
    "            overlay[mask_slice > 0.1, 0] = 1.0  # Červená pro léze\n",
    "            overlay[mask_slice > 0.1, 1] = 0.0  # Snížíme zelenou\n",
    "            overlay[mask_slice > 0.1, 2] = 0.0  # Snížíme modrou\n",
    "            \n",
    "            im4 = axes[1, 0].imshow(overlay)\n",
    "            axes[1, 0].set_title('4. Pseudozdravý obraz s vyznačenými lézemi')\n",
    "            axes[1, 0].axis('off')\n",
    "            \n",
    "            # Výpočet MAE pro aktuální řez, pouze v oblasti léze\n",
    "            mask_region_slice = mask_slice > 0.1\n",
    "            lesion_pixels_in_slice = np.sum(mask_region_slice)\n",
    "            \n",
    "            if lesion_pixels_in_slice > 0:\n",
    "                mae_lesion_slice = np.mean(np.abs(reconstructed_output[z_slice][mask_region_slice] - adc_data[z_slice][mask_region_slice]))\n",
    "                input_vs_output_mae = np.mean(np.abs(reconstructed_output[z_slice][mask_region_slice] - ph_data[z_slice][mask_region_slice]))\n",
    "                slice_mae_values.append((z_slice, mae_lesion_slice, input_vs_output_mae))\n",
    "                \n",
    "                # Výpočet MAE pro celý objem s lézemi, jen pokud máme léze\n",
    "                if lesion_voxel_count > 0:\n",
    "                    mae_lesion_volume = np.sum(np.abs(reconstructed_output[mask_volume] - adc_data[mask_volume])) / lesion_voxel_count\n",
    "                    input_vs_output_mae = np.mean(np.abs(reconstructed_output[z_slice][mask_region_slice] - ph_data[z_slice][mask_region_slice]))\n",
    "                    \n",
    "                    # Přidáme text s MAE skóre pro léze\n",
    "                    fig.suptitle(f'Řez: {z_slice}\\n'\n",
    "                            f'MAE (rekonstrukce vs. target, léze): {mae_lesion_slice:.4f}\\n'\n",
    "                            f'MAE (rekonstrukce vs. pseudozdravý, léze): {input_vs_output_mae:.4f}\\n'\n",
    "                            f'Počet pixelů s lézí v tomto řezu: {lesion_pixels_in_slice} z celkem {lesion_voxel_count} voxelů', \n",
    "                            fontsize=16)\n",
    "                else:\n",
    "                    fig.suptitle(f'Řez: {z_slice}\\n'\n",
    "                                f'V tomto řezu jsou léze, ale v celém objemu není dostatek lézí pro MAE\\n'\n",
    "                                f'Počet pixelů s lézí v tomto řezu: {lesion_pixels_in_slice}', \n",
    "                                fontsize=16)\n",
    "            else:\n",
    "                fig.suptitle(f'Řez: {z_slice}\\n'\n",
    "                            f'V tomto řezu nejsou léze', \n",
    "                            fontsize=16)\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.96])  # Zajistíme místo pro nadpis\n",
    "            \n",
    "            # Přidáme obrázek do PDF\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "        \n",
    "        # Vytvoříme také souhrnnou vizualizaci vývoje MAE pro tento subjekt\n",
    "        if len(slice_mae_values) > 0:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Rozbalíme hodnoty z seznamu\n",
    "            z_values, output_vs_target_values, input_vs_output_values = zip(*slice_mae_values)\n",
    "            \n",
    "            # Graf s dvěma y-osami pro lepší zobrazení\n",
    "            fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "            \n",
    "            # První osa - MAE output vs. target (modrá)\n",
    "            color = 'tab:blue'\n",
    "            ax1.set_xlabel('Číslo řezu')\n",
    "            ax1.set_ylabel('MAE (rekonstrukce vs. target)', color=color)\n",
    "            ax1.plot(z_values, output_vs_target_values, 'o-', color=color, markersize=8, label='MAE (rekonstrukce vs. target)')\n",
    "            ax1.tick_params(axis='y', labelcolor=color)\n",
    "            \n",
    "            # Druhá osa - MAE input vs. output (červená)\n",
    "            ax2 = ax1.twinx()\n",
    "            color = 'tab:red'\n",
    "            ax2.set_ylabel('MAE (pseudozdravý vs. rekonstrukce)', color=color)\n",
    "            ax2.plot(z_values, input_vs_output_values, 'o-', color=color, markersize=8, label='MAE (pseudozdravý vs. rekonstrukce)')\n",
    "            ax2.tick_params(axis='y', labelcolor=color)\n",
    "            \n",
    "            # Přidáme průměrné hodnoty jako horizontální čáry\n",
    "            avg_output_vs_target = np.mean(output_vs_target_values)\n",
    "            avg_input_vs_output = np.mean(input_vs_output_values)\n",
    "            \n",
    "            ax1.axhline(y=avg_output_vs_target, color='tab:blue', linestyle='--', \n",
    "                    label=f'Průměr rekonstrukce vs. target: {avg_output_vs_target:.4f}')\n",
    "            ax2.axhline(y=avg_input_vs_output, color='tab:red', linestyle='--',\n",
    "                    label=f'Průměr pseudozdravý vs. rekonstrukce: {avg_input_vs_output:.4f}')\n",
    "            \n",
    "            # Sloučíme legendy z obou os\n",
    "            lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "            ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2)\n",
    "            \n",
    "            plt.title(f'Porovnání metrik MAE v jednotlivých řezech s lézemi')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            # Přidáme graf do PDF\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "    \n",
    "    print(f\"Vytvořen PDF soubor: {pdf_path}\")\n",
    "\n",
    "def visualize_results(inputs, targets, masks, outputs, epoch, output_dir, subject_ids=None):\n",
    "    \"\"\"\n",
    "    Vytvoří a uloží 3 typy vizualizací pro každou epochu:\n",
    "    1. PDF soubor s detailními vizualizacemi všech řezů\n",
    "    2. PNG soubor s přehledným grafem MAE pro všechny subjekty\n",
    "    3. CSV soubor s numerickými výsledky pro další analýzu\n",
    "    \n",
    "    Args:\n",
    "        inputs: Tensor vstupů (pseudo-zdravých obrazů)\n",
    "        targets: Tensor cílů (ADC s lézemi)\n",
    "        masks: Tensor masek lézí\n",
    "        outputs: Tensor výstupů modelu\n",
    "        epoch: Číslo epochy\n",
    "        output_dir: Adresář pro uložení vizualizací\n",
    "        subject_ids: Volitelně ID subjektů pro pojmenování souborů\n",
    "    \"\"\"\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    import pandas as pd\n",
    "    \n",
    "    viz_dir = os.path.join(output_dir, 'visualizations')\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    print(f\"Vytvářím vizualizace pro epochu {epoch} do adresáře {viz_dir}\")\n",
    "    \n",
    "    # Převod na numpy pro vizualizaci\n",
    "    inputs_np = inputs.detach().cpu().numpy()\n",
    "    targets_np = targets.detach().cpu().numpy()\n",
    "    masks_np = masks.detach().cpu().numpy()\n",
    "    outputs_np = outputs.detach().cpu().numpy()\n",
    "    \n",
    "    batch_size = inputs.shape[0]\n",
    "    \n",
    "    # Data pro CSV a souhrnný graf\n",
    "    summary_data = []\n",
    "    \n",
    "    # Pro každý subjekt v dávce\n",
    "    for b in range(batch_size):\n",
    "        # Najdeme všechny řezy, které obsahují léze\n",
    "        z_slices_with_lesions = np.where(np.any(masks_np[b, 0] > 0.1, axis=(1, 2)))[0]\n",
    "        \n",
    "        # Pokud nemáme žádné léze, zobrazíme alespoň jeden řez ve středu objemu\n",
    "        if len(z_slices_with_lesions) == 0:\n",
    "            z_slices_with_lesions = [inputs_np.shape[2] // 2]\n",
    "            print(f\"Subjekt {subject_ids[b] if subject_ids is not None else f'batch_{b}'}: Nenalezeny žádné léze\")\n",
    "        else:\n",
    "            print(f\"Subjekt {subject_ids[b] if subject_ids is not None else f'batch_{b}'}: Nalezeno {len(z_slices_with_lesions)} řezů s lézemi\")\n",
    "        \n",
    "        # Výpočet MAE pro celý objem s lézemi\n",
    "        mask_volume = masks_np[b, 0] > 0.1\n",
    "        lesion_voxel_count = np.sum(mask_volume)\n",
    "        \n",
    "        if lesion_voxel_count > 0:\n",
    "            mae_lesion_volume = np.sum(np.abs(outputs_np[b, 0][mask_volume] - targets_np[b, 0][mask_volume])) / lesion_voxel_count\n",
    "            \n",
    "            # Uložíme data pro CSV\n",
    "            subject_info = {\n",
    "                'epoch': epoch,\n",
    "                'subject_id': subject_ids[b] if subject_ids is not None else f'batch_{b}',\n",
    "                'lesion_voxel_count': lesion_voxel_count,\n",
    "                'mae_lesion_volume': mae_lesion_volume,\n",
    "                'slices_with_lesions': len(z_slices_with_lesions)\n",
    "            }\n",
    "            \n",
    "            # Přidáme MAE pro každý řez s lézemi\n",
    "            slice_mae_values = []\n",
    "            for z in z_slices_with_lesions:\n",
    "                mask_region = masks_np[b, 0, z] > 0.1\n",
    "                if np.any(mask_region):\n",
    "                    slice_mae = np.mean(np.abs(outputs_np[b, 0, z][mask_region] - targets_np[b, 0, z][mask_region]))\n",
    "                    slice_mae_values.append((z_slice, mae_lesion_slice, input_vs_output_mae))\n",
    "                    subject_info[f'slice_{z}_mae'] = slice_mae\n",
    "                    subject_info[f'slice_{z}_lesion_pixels'] = np.sum(mask_region)\n",
    "            \n",
    "            summary_data.append(subject_info)\n",
    "        else:\n",
    "            mae_lesion_volume = 0\n",
    "        \n",
    "        # 1. SOUBOR - PDF s detailními vizualizacemi všech řezů\n",
    "        if subject_ids is not None:\n",
    "            pdf_filename = f'epoch_{epoch:03d}_subject_{subject_ids[b]}_all_slices.pdf'\n",
    "        else:\n",
    "            pdf_filename = f'epoch_{epoch:03d}_batch_{b:02d}_all_slices.pdf'\n",
    "        \n",
    "        pdf_path = os.path.join(viz_dir, pdf_filename)\n",
    "        \n",
    "        with PdfPages(pdf_path) as pdf:\n",
    "            # Nejprve vytvoříme souhrnnou stránku s informacemi\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.text(0.5, 0.5, \n",
    "                     f\"Vizualizace pro epochu {epoch}\\nSubjekt: {subject_ids[b] if subject_ids is not None else f'batch_{b}'}\\n\"\n",
    "                     f\"Počet řezů s lézemi: {len(z_slices_with_lesions)}\\n\"\n",
    "                     f\"Celkový počet voxelů s lézí: {lesion_voxel_count}\\n\"\n",
    "                     f\"MAE pro celý objem lézí: {mae_lesion_volume:.4f}\", \n",
    "                     ha='center', va='center', fontsize=16)\n",
    "            plt.axis('off')\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "            \n",
    "            # Pro každý řez s lézí vytvoříme vizualizaci\n",
    "            for z_slice in z_slices_with_lesions:\n",
    "                # Vytvoříme figure se 4 subplot podle požadavků\n",
    "                fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "                \n",
    "                # Normalizace pro lepší vizualizaci\n",
    "                norm = Normalize(vmin=0, vmax=1)\n",
    "                \n",
    "                # 1. Output modelu (vpravo nahoře)\n",
    "                im1 = axes[0, 1].imshow(outputs_np[b, 0, z_slice], cmap='gray', norm=norm)\n",
    "                axes[0, 1].set_title('1. Výstup modelu (rekonstrukce)')\n",
    "                axes[0, 1].axis('off')\n",
    "                plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, pad=0.04)\n",
    "                \n",
    "                # 2. Target mapa (ADC s lézemi) (vpravo dole)\n",
    "                im2 = axes[1, 1].imshow(targets_np[b, 0, z_slice], cmap='gray', norm=norm)\n",
    "                axes[1, 1].set_title('2. Target (ADC s lézemi)')\n",
    "                axes[1, 1].axis('off')\n",
    "                plt.colorbar(im2, ax=axes[1, 1], fraction=0.046, pad=0.04)\n",
    "                \n",
    "                # 3. Původní pseudozdravý obraz (vlevo nahoře)\n",
    "                im3 = axes[0, 0].imshow(inputs_np[b, 0, z_slice], cmap='gray', norm=norm)\n",
    "                axes[0, 0].set_title('3. Původní pseudozdravý obraz')\n",
    "                axes[0, 0].axis('off')\n",
    "                plt.colorbar(im3, ax=axes[0, 0], fraction=0.046, pad=0.04)\n",
    "                \n",
    "                # 4. Pseudozdravý obraz se zakreslenými lézemi (vlevo dole)\n",
    "                # Vytvoříme RGB obrázek s červeně vyznačenými lézemi\n",
    "                overlay = np.zeros((inputs_np.shape[3], inputs_np.shape[4], 3))\n",
    "                overlay[:, :, 0] = inputs_np[b, 0, z_slice]  # R kanál - vstup\n",
    "                overlay[:, :, 1] = inputs_np[b, 0, z_slice]  # G kanál - vstup\n",
    "                overlay[:, :, 2] = inputs_np[b, 0, z_slice]  # B kanál - vstup\n",
    "                \n",
    "                # Přidáme léze jako červené oblasti\n",
    "                mask_slice = masks_np[b, 0, z_slice]\n",
    "                overlay[mask_slice > 0.1, 0] = 1.0  # Červená pro léze\n",
    "                overlay[mask_slice > 0.1, 1] = 0.0  # Snížíme zelenou\n",
    "                overlay[mask_slice > 0.1, 2] = 0.0  # Snížíme modrou\n",
    "                \n",
    "                im4 = axes[1, 0].imshow(overlay)\n",
    "                axes[1, 0].set_title('4. Pseudozdravý obraz s vyznačenými lézemi')\n",
    "                axes[1, 0].axis('off')\n",
    "                \n",
    "                # Výpočet MAE pro aktuální řez, pouze v oblasti léze\n",
    "                mask_region_slice = mask_slice > 0.1\n",
    "                lesion_pixels_in_slice = np.sum(mask_region_slice)\n",
    "                \n",
    "                if lesion_pixels_in_slice > 0:\n",
    "                    # MAE mezi výstupem modelu a cílem (ADC s lézemi)\n",
    "                    mae_lesion_slice = np.mean(np.abs(reconstructed_output[z_slice][mask_region_slice] - adc_data[z_slice][mask_region_slice]))\n",
    "                    \n",
    "                    # MAE mezi výstupem modelu a původním pseudozdravým obrazem\n",
    "                    input_vs_output_mae = np.mean(np.abs(reconstructed_output[z_slice][mask_region_slice] - ph_data[z_slice][mask_region_slice]))\n",
    "                    \n",
    "                    slice_mae_values.append((z_slice, mae_lesion_slice, input_vs_output_mae))\n",
    "                    \n",
    "                    # Přidáme text s MAE skóre pro léze\n",
    "                    fig.suptitle(f'Řez: {z_slice}\\n'\n",
    "                                f'MAE (rekonstrukce vs. target, léze): {mae_lesion_slice:.4f}\\n'\n",
    "                                f'MAE (rekonstrukce vs. pseudozdravý, léze): {input_vs_output_mae:.4f}\\n'\n",
    "                                f'Počet pixelů s lézí v tomto řezu: {lesion_pixels_in_slice} z celkem {lesion_voxel_count} voxelů', \n",
    "                                fontsize=16)\n",
    "                    \n",
    "                    # Přidáme text s MAE skóre pro léze\n",
    "                    fig.suptitle(f'Řez: {z_slice}\\n'\n",
    "                                f'MAE (pouze léze - celý objem): {mae_lesion_volume:.4f}, MAE (pouze léze - tento řez): {mae_lesion_slice:.4f}\\n'\n",
    "                                f'Počet pixelů s lézí v tomto řezu: {lesion_pixels_in_slice} z celkem {lesion_voxel_count} voxelů', \n",
    "                                fontsize=16)\n",
    "                else:\n",
    "                    fig.suptitle(f'Řez: {z_slice}\\n'\n",
    "                                f'MAE (pouze léze - celý objem): {mae_lesion_volume:.4f}\\n'\n",
    "                                f'V tomto řezu nejsou léze, celkem {lesion_voxel_count} voxelů s lézí', \n",
    "                                fontsize=16)\n",
    "                \n",
    "                plt.tight_layout(rect=[0, 0, 1, 0.96])  # Zajistíme místo pro nadpis\n",
    "                \n",
    "                # Přidáme obrázek do PDF\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "            \n",
    "            # Vytvoříme také souhrnnou vizualizaci vývoje MAE pro tento subjekt\n",
    "            if len(z_slices_with_lesions) > 0 and lesion_voxel_count > 0:\n",
    "                if slice_mae_values:\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    z_values, mae_values = zip(*slice_mae_values)\n",
    "                    plt.plot(z_values, mae_values, 'o-', markersize=8)\n",
    "                    plt.axhline(y=mae_lesion_volume, color='r', linestyle='--', label=f'Průměrné MAE celého objemu: {mae_lesion_volume:.4f}')\n",
    "                    plt.xlabel('Číslo řezu')\n",
    "                    plt.ylabel('MAE (pouze oblast léze)')\n",
    "                    plt.title(f'MAE v jednotlivých řezech s lézemi')\n",
    "                    plt.grid(True)\n",
    "                    plt.legend()\n",
    "                    \n",
    "                    # Přidáme graf do PDF\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "        \n",
    "        print(f\"Vytvořen PDF soubor: {pdf_path}\")\n",
    "    \n",
    "    # 2. SOUBOR - PNG se souhrnným grafem MAE pro všechny subjekty\n",
    "    if summary_data:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Vytvoříme skupinový sloupcový graf pro MAE všech subjektů\n",
    "        subject_ids_plot = [data['subject_id'] for data in summary_data]\n",
    "        mae_values_plot = [data['mae_lesion_volume'] for data in summary_data]\n",
    "        \n",
    "        plt.bar(subject_ids_plot, mae_values_plot, color='skyblue')\n",
    "        plt.axhline(y=np.mean(mae_values_plot), color='r', linestyle='--', \n",
    "                   label=f'Průměrné MAE všech subjektů: {np.mean(mae_values_plot):.4f}')\n",
    "        \n",
    "        plt.xlabel('Subjekt')\n",
    "        plt.ylabel('MAE (pouze oblast léze)')\n",
    "        plt.title(f'Epocha {epoch}: MAE pro všechny subjekty')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Uložíme souhrnný graf jako PNG\n",
    "        summary_plot_path = os.path.join(viz_dir, f'epoch_{epoch:03d}_summary_mae.png')\n",
    "        plt.savefig(summary_plot_path, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"Vytvořen souhrnný graf: {summary_plot_path}\")\n",
    "    \n",
    "    # 3. SOUBOR - CSV s číselnými výsledky\n",
    "    if summary_data:\n",
    "        # Uložíme data do CSV\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        csv_path = os.path.join(viz_dir, f'epoch_{epoch:03d}_metrics.csv')\n",
    "        summary_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Vytvořen CSV soubor s metrikami: {csv_path}\")\n",
    "    \n",
    "    print(f\"Vizualizace pro epochu {epoch} dokončeny.\")\n",
    "\n",
    "from perceptual_loss import PerceptualLoss3D  # Přidat tento import na začátek souboru\n",
    "\n",
    "def train(args):\n",
    "    # Vytvoření adresářů a TensorBoard writer\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(os.path.join(args.output_dir, 'logs'))\n",
    "\n",
    "    # Inicializace augmentace\n",
    "    augmentation = BrainLesionAugmentation(\n",
    "        rotation_range=(-15, 15),        # Rotace až ±15 stupňů\n",
    "        flip_probability=0.5,            # 50% šance na flip\n",
    "        intensity_shift_range=(-0.1, 0.1), # Posun intenzity ±0.1\n",
    "        intensity_scale_range=(0.9, 1.1),  # Škálování intenzity ±10%\n",
    "        noise_level=0.03                 # 3% šumu\n",
    "    )\n",
    "    \n",
    "    # Vytvoření datasetu a dataloaderu\n",
    "    dataset = BrainLesionDataset(args.csv_path, augmentation=augmentation)\n",
    "    if len(dataset) == 0:\n",
    "        print(\"VAROVÁNÍ: Dataset je prázdný! Zkontrolujte CSV soubor.\")\n",
    "        return\n",
    "    \n",
    "    train_size = max(1, int(0.8 * len(dataset)))\n",
    "    val_size = max(1, len(dataset) - train_size)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "    \n",
    "    # Inicializace zařízení a modelu\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Používám zařízení: {device}\")\n",
    "    model = HIELesionInpainter(args.checkpoint_path, device=device).to(device)\n",
    "    \n",
    "    # Inicializace loss funkcí\n",
    "    mse_loss = nn.MSELoss()\n",
    "    l1_loss = nn.L1Loss()\n",
    "    \n",
    "    # Inicializace perceptual loss\n",
    "    perceptual_loss = PerceptualLoss3D(num_slices=3)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        perceptual_loss = perceptual_loss.cuda()\n",
    "    # Koeficient pro vážení perceptual loss (hodnotu lze experimentálně upravit)\n",
    "    perceptual_weight = 0.1\n",
    "    \n",
    "    # Inicializace optimizeru – filtrujeme pouze parametry, které vyžadují gradient\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n",
    "    \n",
    "    # Hlavní tréninkový cyklus (změna: použití args.num_epochs dle instrukcí)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        model.train()\n",
    "        total_recon_loss = 0\n",
    "        total_perceptual_loss = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs = batch['input'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            masks = batch['mask'].to(device)\n",
    "            \n",
    "            # Forward pass – předpokládáme, že model vrací přímo rekonstruované výstupy\n",
    "            outputs = model(inputs, masks)\n",
    "            \n",
    "            # Výpočet rekonstrukční loss pomocí MSE\n",
    "            recon_loss = mse_loss(outputs, targets)\n",
    "            \n",
    "            # Výpočet perceptual loss\n",
    "            p_loss = perceptual_loss(outputs, targets)\n",
    "            \n",
    "            # Celková loss jako kombinace obou složek\n",
    "            loss = recon_loss + perceptual_weight * p_loss\n",
    "            \n",
    "            # Pro výpis do logu akumulujeme hodnoty loss\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_perceptual_loss += p_loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{args.num_epochs}, Batch {i}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        avg_recon_loss = total_recon_loss / len(train_loader)\n",
    "        avg_perceptual_loss = total_perceptual_loss / len(train_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{args.num_epochs}, Recon Loss: {avg_recon_loss:.4f}, Perceptual Loss: {avg_perceptual_loss:.4f}\")\n",
    "        \n",
    "        writer.add_scalar('Loss/train_recon', avg_recon_loss, epoch)\n",
    "        writer.add_scalar('Loss/train_perceptual', avg_perceptual_loss, epoch)\n",
    "        \n",
    "        # --- Validace ---\n",
    "        model.eval()\n",
    "        total_val_recon_loss = 0\n",
    "        total_val_perceptual_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = batch['input'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                masks = batch['mask'].to(device)\n",
    "                \n",
    "                outputs = model(inputs, masks)\n",
    "                val_recon_loss = mse_loss(outputs, targets)\n",
    "                val_p_loss = perceptual_loss(outputs, targets)\n",
    "                loss_val = val_recon_loss + perceptual_weight * val_p_loss\n",
    "                \n",
    "                total_val_recon_loss += val_recon_loss.item()\n",
    "                total_val_perceptual_loss += val_p_loss.item()\n",
    "        \n",
    "        avg_val_recon_loss = total_val_recon_loss / len(val_loader)\n",
    "        avg_val_perceptual_loss = total_val_perceptual_loss / len(val_loader)\n",
    "        \n",
    "        writer.add_scalar('Loss/val_recon', avg_val_recon_loss, epoch)\n",
    "        writer.add_scalar('Loss/val_perceptual', avg_val_perceptual_loss, epoch)\n",
    "        print(f\"Validation - Recon Loss: {avg_val_recon_loss:.4f}, Perceptual Loss: {avg_val_perceptual_loss:.4f}\")\n",
    "        \n",
    "        # Uložení checkpointu každých 5 epoch nebo poslední epochy\n",
    "        if (epoch + 1) % 5 == 0 or epoch == args.num_epochs - 1:\n",
    "            checkpoint_path = os.path.join(args.output_dir, f'model_epoch{epoch+1}.pt')\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    # Uložení finálního modelu\n",
    "    final_path = os.path.join(args.output_dir, 'final_model.pt')\n",
    "    torch.save(model.state_dict(), final_path)\n",
    "    print(f'Training completed. Final model saved to {final_path}')\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Fine-tune brain2vec for HIE lesion inpainting')\n",
    "    parser.add_argument('--checkpoint_path', type=str, required=True, help='Path to pretrained brain2vec model')\n",
    "    parser.add_argument('--csv_path', type=str, required=True, help='Path to CSV file with data')\n",
    "    parser.add_argument('--output_dir', type=str, default='./output', help='Output directory')\n",
    "    parser.add_argument('--batch_size', type=int, default=2, help='Batch size')\n",
    "    parser.add_argument('--n_epochs', type=int, default=10, help='Number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    train(args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/brain2vec\n",
    "\n",
    "!python /kaggle/working/brain2vec/preprocess_data.py\n",
    "\n",
    "# Spuštění fine-tuningu\n",
    "!python finetune_hie_lesions.py \\\n",
    "  --checkpoint_path ./autoencoder_final.pth \\\n",
    "  --csv_path ./inputs.csv \\\n",
    "  --output_dir /kaggle/working/hie_output \\\n",
    "  --batch_size 1 \\\n",
    "  --n_epochs 20"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
